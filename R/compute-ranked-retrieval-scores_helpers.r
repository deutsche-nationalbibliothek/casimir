#' Helper Function for document-wise computation of ranked retrieval scores
#' dcg, ndcg and lrap
#'
#' @param gold_vs_pred a \code{data.frame} as generated by create_comparison
#'   a column \emph{"score"} is expected
#' @param grouping_var character vector of variables that must be present in
#'  base_compare
#'
#' @return a \code{data.frame} with cols \emph{"dcg", "idcg", "ndcg", "lrap"}
#'
#' @examples
#'
#' gold <- tibble::tribble(
#'   ~doc_id, ~label_id,
#'   "A", "a",
#'   "A", "b",
#'   "A", "c",
#'   "A", "d",
#'   "A", "e",
#' )
#'
#' pred <- tibble::tribble(
#'   ~doc_id, ~label_id, ~score,
#'   "A", "f",	0.3277,
#'   "A", "e",	0.32172,
#'   "A", "b",	0.13517,
#'   "A", "g",	0.10134,
#'   "A", "h",	0.09152,
#'   "A", "a",	0.07483,
#'   "A", "i",	0.03649,
#'   "A", "j",	0.03551,
#'   "A", "k",	0.03397,
#'   "A", "c",	0.03364
#' )
#'
#' gold_vs_pred <- create_comparison(gold, pred)
#'
#' casimir:::compute_intermediate_results_rr(
#'   gold_vs_pred,
#'   rlang::syms(c("doc_id"))
#' )
compute_intermediate_results_rr <- function(
  gold_vs_pred, grouping_var
) {

  stopifnot(all(c("doc_id", "score", "gold") %in% colnames(gold_vs_pred)))

  gold_vs_pred |>
    dplyr::group_by(!!!grouping_var) |>
    dplyr::arrange(dplyr::desc(score)) |>
    dplyr::mutate(n_gold = sum(gold), n_pred = sum(suggested)) |>
    dplyr::mutate(
      discount = log2(seq_len(dplyr::n()) + 1),
      gain = gold & suggested,
      ideal = c(
        rep_len(1, n_gold[1]),
        rep_len(0, dplyr::n() - n_gold[1])
      ),
      score_tp = dplyr::if_else(gold & suggested, score, NA_real_),
      L = rank(-score_tp, ties.method = "max"),
      rank = rank(-score, ties.method = "max")
    ) |>
    dplyr::summarise(
      dcg = sum(gain / discount),
      idcg = sum(ideal / discount),
      ndcg = dplyr::if_else(idcg > 0, dcg / idcg, 1.0),
      lrap = sum((gold & suggested) * L / rank) / n_gold[1]
    )
}

# Implementierung gemäß
# https://github.com/NatLibFi/Annif/blob/master/annif/eval.py

#' Reference implementation of dcg to test against
#'
#' @param df a \code{data.frame} as generated by create_comparison
#' @param limit cut off value for dcgAtN
dcg_score <- function(df, limit = NULL) {
  # return the discounted cumulative gain (DCG) score for the selected
  #  labels vs. relevant labels

  df <- df |>  dplyr::arrange(dplyr::desc(score))
  n_pred <- sum(!is.na(df$score))
  if (!is.null(limit)) n_pred <- min(limit, n_pred)

  gain <- df$gold[1:n_pred]
  discount <- log2(1:n_pred + 1)

  return(sum(gain / discount))
}

##########################################################################

#' Reference implementation for ndcg to test against
#'
#' @param gold_vs_pred a \code{data.frame} as generated by create_comparison
#' @param limit cut off value for ndcg at N
#'
#' @return numeric value of ndcg
ndcg_score <- function(gold_vs_pred, limit = NULL) {
  # return the normalized discounted cumulative gain (nDCG) score for the
  #  selected labels vs. relevant labels

  scores <- c()

  for (DOC_ID in unique(gold_vs_pred$doc_id)){

    temp <- gold_vs_pred |>  dplyr::filter(doc_id == DOC_ID)

    idcg <- dcg_score(
      temp |> dplyr::mutate(score = gold), limit
    )
    dcg <- dcg_score(
      temp, limit
    )

    if (idcg > 0) {
      scores <- c(scores, dcg / idcg)
    } else {
      scores <- c(scores, 1.0)
    }

  }

  return(mean(scores, na.rm = TRUE))
}

#' Reference implementation for Label Ranking Average Precision
#'
#' @param gold_vs_pred  a \code{data.frame} as generated by create_comparison
#'
#' @return numeric value of lrap
lrap_score <- function(gold_vs_pred) {
  # Compute ranking-based average precision.

  out <- c()

  for (DOC_ID in unique(gold_vs_pred$doc_id)){

    temp <- gold_vs_pred |>
      dplyr::filter(doc_id == DOC_ID) |>
      dplyr::mutate(score = tidyr::replace_na(score, 0))

    relevant <- which(temp$gold)

    if (length(relevant) == 0) {
      aux <- 1.0
    } else {
      scores_i <- -temp$score
      rank <- rank(scores_i, ties.method = "max")[relevant]
      L <- rank(scores_i[relevant], ties.method = "max")

      # Manuelle Korrektur für False Negatives: L / rank = #TP / n_samples ~ 0
      aux <- mean((scores_i[relevant] < 0) * L / rank)
    }

    out <- c(out, aux)
  }

  return(mean(out, na.rm = TRUE))
}

