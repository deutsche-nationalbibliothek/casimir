% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/compute_pr_curve.r
\name{compute_pr_curve}
\alias{compute_pr_curve}
\title{compute precision-recall-curve for a given step size and limit_range}
\usage{
compute_pr_curve(
  gold_standard,
  predicted,
  doc_groups = NULL,
  label_groups = NULL,
  mode = "doc-avg",
  steps = 100,
  thresholds = NULL,
  limit_range = NA_real_,
  optimize_cutoff = FALSE,
  graded_relevance = FALSE,
  propensity_scored = FALSE,
  label_distribution = NULL,
  cost_fp_constant = NULL,
  ignore_inconsistencies = options::opt("ignore_inconsistencies"),
  verbose = options::opt("verbose"),
  progress = options::opt("progress")
)
}
\arguments{
\item{gold_standard}{expects \code{data.frame} with cols
\emph{"label_id", "doc_id"}}

\item{predicted}{multi-label prediction results. expects \code{data.frame}
with cols \emph{"label_id", "doc_id", "score"}}

\item{doc_groups}{two-column \code{data.frame} with col \emph{"doc_id"}
and a second column that defines groups of labels to stratify results by.
It is recommended that groups are of type factor, so that levels are
not implicitly dropped during bootstrap replications}

\item{label_groups}{two-column \code{data.frame} with col \emph{"label_id"}
and a second column that defines groups of labels to stratify results by.
Results in each stratum
will restrict gold_standard and predictions to the specified label-groups,
as if the vocabulary was consisting of the label group only.
All modes \code{c("doc-avg", "subj-avg", "micro") } are supported within
label-strata.
Nevertheless, mixing \code{mode = "doc-avg"} with fine-grained
label_strata can result in many missing values on document-level results.
Also rank-based thresholding (e.g. Top-5) will result in inhomogeneous
number of labels per documents within the defined label-strata.
\code{mode = "subj-avg"} or \code{mode = "micro"} can be more appropriate
in these circumstances.}

\item{mode}{aggregation mode: \emph{"doc-avg", "subj-avg", "micro"}}

\item{steps}{how many steps to take between c(0,1) as a grid for computing
the pr-curve}

\item{thresholds}{alternatively to steps, one can manually set, which
thresholds are used to build the pr_curve. Defaults to \code{steps}-percentiles
of the score distribution of true positives suggestions}

\item{limit_range}{a vector of limit values to apply on rank-column.
Defaults to NA, applying no cutoff on label-rank of predictions.}

\item{optimize_cutoff}{logical. If \code{TRUE} performs a grid search to
find optimal limit and threshold  with respect to f1-measure in the
search space specified by \code{limit_range} and \code{steps}.}

\item{graded_relevance}{logical indicator for graded relevance. Defaults to
\code{FALSE} for binary relevance. If set to \code{TRUE}, the
\code{predicted} data.frame should contain a numeric column
\emph{"relevance"} with values in the range of \code{c(0, 1)}.}

\item{propensity_scored}{logical, whether to use propensity scores as weights}

\item{label_distribution}{expects \code{data.frame} with cols
\emph{"label_id", "label_freq", "n_docs"}. \code{label_freq} corresonds to
the number of occurences a label has in the gold_standard. \code{n_docs}
corresponds to the total number of documents in the gold_standard.}

\item{cost_fp_constant}{Constant cost assigned to false positives.
cost_fp_constant must be
a numeric value > 0 or one of 'max', 'min', 'mean' (computed with reference
to the \code{gold_standard} label distribution). The default is NULL, i.e.
label weights are applied to false positives as to false negatives and
true positives.}

\item{ignore_inconsistencies}{Warnings about data inconsistencies will be silenced. (Defaults to \code{FALSE}, overwritable using option 'casimir.ignore_inconsistencies' or environment variable 'R_CASIMIR_IGNORE_INCONSISTENCIES')}

\item{verbose}{Verbose reorting of computation steps for debugging (Defaults to \code{FALSE}, overwritable using option 'casimir.verbose' or environment variable 'R_CASIMIR_VERBOSE')}

\item{progress}{Display progress bars for iterated computations (like bootstrap CI or
PR-Curves) (Defaults to \code{FALSE}, overwritable using option 'casimir.progress' or environment variable 'R_CASIMIR_PROGRESS')}
}
\value{
a \code{list} with of two elemets:
\enumerate{
\item \code{plot_data} a \code{data.frame} with cols
\code{c("searchspace_id", "prec", "rec", "prec_cummax")}
\item \code{opt_cutoff} a \code{data.frame} with cols
\code{c("thresholds", "limits", "f1_max",
      "prec", "rec", "prec_cummax")}
}

and possibly additional stratification variables passed with doc_groups
and label_groups
}
\description{
compute precision-recall-curve for a given step size and limit_range
}
\examples{

library(ggplot2)
library(casimir)

gold <- tibble::tribble(
~doc_id, ~label_id,
"A", "a",
"A", "b",
"A", "c",
"B", "a",
"B", "d",
"C", "a",
"C", "b",
"C", "d",
"C", "f"
)

pred <- tibble::tribble(
  ~doc_id, ~label_id, ~score, ~rank,
  "A", "a", 0.9, 1,
  "A", "d", 0.7, 2,
  "A", "f", 0.3, 3,
  "A", "c", 0.1, 4,
  "B", "a", 0.8, 1,
  "B", "e", 0.6, 2,
  "B", "d", 0.1, 3,
  "C", "f", 0.1, 1,
  "C", "c", 0.2, 2,
  "C", "e", 0.2, 2
)

pr_curve <- compute_pr_curve(
  gold,
  pred,
  mode = "doc-avg",
  optimize_cutoff = TRUE
)

auc <- compute_pr_auc_from_curve(pr_curve$plot_data)


# note that pr-curves take the cummax(prec), not the precision
ggplot(pr_curve$plot_data,   aes(x = rec, y = prec_cummax)) +
  geom_point(data = pr_curve$opt_cutoff,
             aes(x = rec, y = prec_cummax),
             color = "red",
             shape = "star"
  ) +
  geom_text(data = pr_curve$opt_cutoff,
            aes(x = rec + 0.2, y = prec_cummax,
            label = paste("f1_opt =", round(f1_max,3))),
            color = "red"
  ) +
  geom_path() +
  coord_cartesian(xlim = c(0,1), ylim = c(0,1))
}
